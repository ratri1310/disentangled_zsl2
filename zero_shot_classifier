import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import faiss
from typing import Dict, List, Tuple, Optional
from sklearn.metrics import precision_recall_fscore_support, roc_auc_score
from tqdm import tqdm

class ZeroShotClassifier(nn.Module):
    """
    Zero-shot classifier using semantic similarity with MeSH anchors.
    """
    
    def __init__(self, 
                 anchor_embeddings: torch.Tensor,
                 mesh_codes: List[str],
                 similarity_threshold: float = 0.5,
                 top_k: int = 10):
        super().__init__()
        
        self.register_buffer('anchor_embeddings', anchor_embeddings)
        self.mesh_codes = mesh_codes
        self.similarity_threshold = similarity_threshold
        self.top_k = top_k
        
        # Create code to index mapping
        self.code_to_idx = {code: idx for idx, code in enumerate(mesh_codes)}
        self.idx_to_code = {idx: code for idx, code in enumerate(mesh_codes)}
        
        # Initialize FAISS index for efficient similarity search
        self.faiss_index = None
        self._build_faiss_index()
    
    def _build_faiss_index(self):
        """Build FAISS index for efficient nearest neighbor search."""
        embedding_dim = self.anchor_embeddings.size(1)
        
        # Normalize embeddings for cosine similarity
        normalized_anchors = F.normalize(self.anchor_embeddings, dim=1)
        
        # Create FAISS index
        self.faiss_index = faiss.IndexFlatIP(embedding_dim)  # Inner product for cosine similarity
        self.faiss_index.add(normalized_anchors.cpu().numpy().astype(np.float32))
    
    def compute_similarities(self, content_features: torch.Tensor) -> torch.Tensor:
        """
        Compute cosine similarities between content features and all anchors.
        
        Args:
            content_features: Content features z_I [batch_size, dim]
            
        Returns:
            Similarity scores [batch_size, num_anchors]
        """
        # Normalize features
        content_norm = F.normalize(content_features, dim=1)
        anchor_norm = F.normalize(self.anchor_embeddings, dim=1)
        
        # Compute cosine similarities
        similarities = torch.mm(content_norm, anchor_norm.t())
        
        return similarities
    
    def predict_top_k(self, 
                     content_features: torch.Tensor, 
                     k: Optional[int] = None) -> Tuple[torch.Tensor, torch.Tensor, List[List[str]]]:
        """
        Predict top-k most similar MeSH codes.
        
        Args:
            content_features: Content features [batch_size, dim]
            k: Number of top predictions (defaults to self.top_k)
            
        Returns:
            Tuple of (similarities, indices, mesh_codes)
        """
        if k is None:
            k = self.top_k
        
        # Compute similarities
        similarities = self.compute_similarities(content_features)
        
        # Get top-k
        top_similarities, top_indices = torch.topk(similarities, k, dim=1)
        
        # Convert indices to MeSH codes
        batch_mesh_codes = []
        for batch_idx in range(top_indices.size(0)):
            mesh_codes = [self.idx_to_code[idx.item()] for idx in top_indices[batch_idx]]
            batch_mesh_codes.append(mesh_codes)
        
        return top_similarities, top_indices, batch_mesh_codes
    
    def predict_binary(self, content_features: torch.Tensor) -> torch.Tensor:
        """
        Predict binary labels based on similarity threshold.
        
        Args:
            content_features: Content features [batch_size, dim]
            
        Returns:
            Binary predictions [batch_size, num_classes]
        """
        similarities = self.compute_similarities(content_features)
        predictions = (similarities > self.similarity_threshold).float()
        
        return predictions
    
    def faiss_search(self, 
                    content_features: torch.Tensor, 
                    k: Optional[int] = None) -> Tuple[np.ndarray, np.ndarray]:
        """
        Efficient top-k search using FAISS.
        
        Args:
            content_features: Content features [batch_size, dim]
            k: Number of top predictions
            
        Returns:
            Tuple of (similarities, indices)
        """
        if k is None:
            k = self.top_k
        
        # Normalize features
        content_norm = F.normalize(content_features, dim=1)
        query_vectors = content_norm.cpu().numpy().astype(np.float32)
        
        # Search using FAISS
        similarities, indices = self.faiss_index.search(query_vectors, k)
        
        return similarities, indices
    
    def forward(self, content_features: torch.Tensor) -> Dict[str, torch.Tensor]:
        """
        Forward pass for zero-shot classification.
        
        Args:
            content_features: Content features z_I
            
        Returns:
            Dictionary of predictions and similarities
        """
        # Compute similarities
        similarities = self.compute_similarities(content_features)
        
        # Binary predictions
        binary_predictions = (similarities > self.similarity_threshold).float()
        
        # Top-k predictions
        top_similarities, top_indices, _ = self.predict_top_k(content_features)
        
        return {
            'similarities': similarities,
            'binary_predictions': binary_predictions,
            'top_similarities': top_similarities,
            'top_indices': top_indices
        }

class ZeroShotEvaluator:
    """
    Evaluator for zero-shot classification performance.
    """
    
    def __init__(self, mesh_codes: List[str]):
        self.mesh_codes = mesh_codes
        self.code_to_idx = {code: idx for idx, code in enumerate(mesh_codes)}
    
    def compute_metrics(self, 
                       similarities: torch.Tensor, 
                       true_labels: torch.Tensor,
                       thresholds: List[float] = None) -> Dict[str, float]:
        """
        Compute comprehensive evaluation metrics.
        
        Args:
            similarities: Predicted similarities [batch_size, num_classes]
            true_labels: True binary labels [batch_size, num_classes]
            thresholds: List of thresholds to evaluate
            
        Returns:
            Dictionary of metrics
        """
        if thresholds is None:
            thresholds = [0.1, 0.3, 0.5, 0.7, 0.9]
        
        similarities_np = similarities.cpu().numpy()
        true_labels_np = true_labels.cpu().numpy()
        
        metrics = {}
        
        # AUC-ROC (macro and micro)
        try:
            auc_macro = roc_auc_score(true_labels_np, similarities_np, average='macro')
            auc_micro = roc_auc_score(true_labels_np, similarities_np, average='micro')
            metrics['auc_macro'] = auc_macro
            metrics['auc_micro'] = auc_micro
        except ValueError:
            metrics['auc_macro'] = 0.0
            metrics['auc_micro'] = 0.0
        
        # Threshold-based metrics
        for threshold in thresholds:
            predictions = (similarities > threshold).float().cpu().numpy()
            
            # Precision, Recall, F1
            precision, recall, f1, _ = precision_recall_fscore_support(
                true_labels_np, predictions, average='macro', zero_division=0
            )
            
            # Exact match accuracy
            exact_match = np.mean(np.all(predictions == true_labels_np, axis=1))
            
            # Hamming accuracy
            hamming_acc = np.mean(predictions == true_labels_np)
            
            # Hamming loss
            hamming_loss = np.mean(predictions != true_labels_np)
            
            # Store metrics
            metrics[f'precision_@{threshold}'] = precision
            metrics[f'recall_@{threshold}'] = recall
            metrics[f'f1_@{threshold}'] = f1
            metrics[f'exact_match_@{threshold}'] = exact_match
            metrics[f'hamming_acc_@{threshold}'] = hamming_acc
            metrics[f'hamming_loss_@{threshold}'] = hamming_loss
        
        return metrics
    
    def compute_ranking_metrics(self, 
                               similarities: torch.Tensor,
                               true_labels: torch.Tensor,
                               k_values: List[int] = None) -> Dict[str, float]:
        """
        Compute ranking-based metrics (Precision@K, Recall@K, NDCG@K).
        
        Args:
            similarities: Predicted similarities
            true_labels: True binary labels
            k_values: List of k values for evaluation
            
        Returns:
            Dictionary of ranking metrics
        """
        if k_values is None:
            k_values = [1, 3, 5, 10, 20]
        
        batch_size = similarities.size(0)
        metrics = {}
        
        for k in k_values:
            precisions_k = []
            recalls_k = []
            ndcgs_k = []
            
            for i in range(batch_size):
                # Get top-k predictions
                top_similarities, top_indices = torch.topk(similarities[i], k)
                
                # Create binary prediction vector
                pred_k = torch.zeros_like(similarities[i])
                pred_k[top_indices] = 1
                
                # True positives
                true_positives = (pred_k * true_labels[i]).sum().item()
